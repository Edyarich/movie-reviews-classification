"""
Shared message definitions and text‑preprocessing helpers.

You’ll re‑use the same module from *both* the gateway container and,
later, the dedicated model‑server container.  If you decide to migrate
to real gRPC, this file will be auto‑generated by `protoc`; for now we
keep it hand‑written for simplicity.
"""
from dataclasses import dataclass
from typing import List

import numpy as np
import pandas as pd


# ────────────────────────────────
# Message “schemas”
# ────────────────────────────────
@dataclass
class PredictRequest:
    """Incoming request from the gateway to the model service."""
    review: str


@dataclass
class PredictResponse:
    """Model‑service reply sent back through the gateway."""
    prediction: str   # "positive" or "negative"
    score: float

# ────────────────────────────────
# Pre‑processing utilities
# ────────────────────────────────
def preprocess_text(df: pd.DataFrame) -> None:
    """
    Convert to lower‑case, strip HTML and non‑alphanumerics (in‑place).
    """
    df["review"] = (
        df["review"]
        .str.lower()
        .str.replace(r"[^\w\s]", "", regex=True)
        .str.replace("<br />", "", regex=False)
    )


def preprocess_test_data(df: pd.DataFrame, metadata: dict) -> np.ndarray:
    """
    Tokenise and left‑pad a DataFrame of reviews using `metadata[tokenizer]`.
    """
    preprocess_text(df)

    tokenizer = metadata["tokenizer"]
    max_length = metadata["max_length"]
    encoded = [tokenizer.encode_as_ids(t) for t in df["review"].values]
    padded: List[np.ndarray] = [
        np.pad(seq, (0, max(0, max_length - len(seq))), "constant")[:max_length]
        for seq in encoded
    ]
    return np.asarray(padded, dtype=np.int32)
